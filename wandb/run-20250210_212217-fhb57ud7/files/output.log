Hyper-parameters:
 {'dataset': 'HMDB51', 'method': 'DM', 'model': 'ConvNet3D', 'ipc': 1, 'eval_mode': 'SS', 'outer_loop': 1, 'inner_loop': 1, 'num_eval': 1, 'eval_it': 500, 'epoch_eval_train': 500, 'Iteration': 5000, 'lr_net': 0.01, 'lr_img': 30.0, 'lr_lr': 1e-05, 'lr_teacher': 0.001, 'train_lr': False, 'batch_real': 16, 'batch_train': 256, 'batch_syn': 51, 'init': 'real', 'data_path': 'distill_utils/data', 'expert_epochs': 3, 'syn_steps': 64, 'max_start_epoch': 25, 'dis_metric': 'ours', 'buffer_path': None, 'num_workers': 4, 'preload': True, 'save_path': './logged_files', 'frames': 16, 'vae_path': './vae_weights', 'device': 'cuda', '_wandb': {}, 'distributed': False}
Evaluation model pool:  ['ConvNet3D']
BUILDING DATASET
2618it [00:00, 741737.90it/s]
C:\Users\linin\OneDrive\Desktop\Dataset Condensation\Video Distillation\distillation_w_vae\baseline.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels_all = torch.tensor(labels_all, dtype=torch.long, device="cpu")
initialize synthetic data from random real images
Encoding the synthesis videos into the latent space
100%|â–ˆ| 13
Traceback (most recent call last):
  File "C:\Users\linin\OneDrive\Desktop\Dataset Condensation\Video Distillation\distillation_w_vae\baseline.py", line 320, in <module>
    main(args)
  File "C:\Users\linin\OneDrive\Desktop\Dataset Condensation\Video Distillation\distillation_w_vae\baseline.py", line 169, in main
    image_syn.data = torch.cat(syn_latents, dims=0)
TypeError: cat() received an invalid combination of arguments - got (list, dims=int), but expected one of:
 * (tuple of Tensors tensors, int dim = 0, *, Tensor out = None)
 * (tuple of Tensors tensors, name dim, *, Tensor out = None)
